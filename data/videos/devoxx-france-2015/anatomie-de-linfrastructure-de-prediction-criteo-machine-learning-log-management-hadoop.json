{
    "description": "Criteo affiche 2 milliards de bannières par jour. Elles nécessitent 15 millions de prédictions par seconde, qui génèrent à leur tour 950GB de données (compressées) par heure. Ces données sont digérées sur Hadoop pour finalement y appliquer des algorithmes de machine learning qui génèrent 1700 modèles de prédiction par jour, utilisés pour les prédictions suivantes. La boucle est bouclée! Nous décrirons en détail l'infrastructure qui permet d'enchaîner les étapes de ce traitement. Son état actuel sera remis dans la perspective des difficultés rencontrées, et nous évoquerons les évolutions futures.\n\n\nAuthors:\nJean-Baptiste Note\nSoftware Engineer @ Criteo\n\nLaurent Vion\nDéveloppeur chez Criteo depuis 5 ans, je travaille principalement sur l’infrastructure technique du composant de prédiction : distribution des calcul, déploiement des modèles, environnement de pré-production et de simulation …",
    "favorite": "0",
    "length": "51:41",
    "likes": "0",
    "recorded": "2015-04-10",
    "speakers": [
        "jean-baptiste-claramonte",
        "laurent-vion"
    ],
    "tags": [],
    "thumbnail_url": "https://i.ytimg.com/vi/p_KdvFPQsQI/hqdefault.jpg",
    "title": "Anatomie de l'infrastructure de prédiction @Criteo: machine learning, log management, Hadoop.",
    "videos": [
        {
            "code": "p_KdvFPQsQI",
            "type": "youtube"
        }
    ],
    "views": "248"
}