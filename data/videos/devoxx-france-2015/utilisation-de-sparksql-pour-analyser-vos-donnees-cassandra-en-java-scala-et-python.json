{
    "description": "Cassandra ne permet ni jointure, ni agrégats et limite drastiquement vos capacités à requêter vos données pour permettre une scalabilité linéaire dans une architecture masterless. L'outil de choix pour effectuer des traitements analytiques sur vos tables Cassandra est Spark mais ce dernier complexifie des opérations pourtant simples en SQL. SparkSQL permet de retrouver une syntaxe SQL dans Spark et nous allons voir comment l'utiliser en Scala, Java et en Python pour travailler sur des tables Cassandra, et retrouver jointures et agrégats (entre autres).\n\n\nAuthors:\nAlexander DEJANOVSKI\nDéveloppeur chez Chronopost\n\nJe me suis pris d'une passion toute particulière pour Apache Cassandra, et compte bien ne pas retravailler sur une base relationnelle de sitôt. Je contribue au driver JDBC \"legacy\" de Cassandra et j'ai récemment terminé sa réécriture pour qu'il utilise le driver Java Datastax au lieu de Thrift.\n\nMaxence Lecointe\nJust passionate about Java.\n\nEvery day is a day to improve coding skills.\n\nGreat experience with Java tools/technologies/frameworks/standards (e.g. Eclipse, Hibernate, Spring, etc.) and software development methods and tools.\n\nCode review.\n\nSoftware architecture and design.\n\nImplementation of innovative technologies.",
    "favorite": "0",
    "length": "27:29",
    "likes": "0",
    "recorded": "2015-04-08",
    "speakers": [
        "alexander-dejanovski",
        "maxence-lecointe"
    ],
    "tags": [],
    "thumbnail_url": "https://i.ytimg.com/vi/lllVEB2SKZY/hqdefault.jpg",
    "title": "Utilisation de SparkSQL pour analyser vos données Cassandra en Java, Scala et Python",
    "videos": [
        {
            "code": "lllVEB2SKZY",
            "type": "youtube"
        }
    ],
    "views": "131"
}