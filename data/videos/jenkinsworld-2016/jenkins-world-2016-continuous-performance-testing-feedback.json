{
    "description": "The discipline of performance testing has sometimes had difficulty keeping up with modern software development/deployment processes and testing principles. Many people still think of performance testing as a single experiment, run against a completely assembled, code-frozen, production-resourced system. Needless to say, the accuracy of simulation and environmental data is only as valuable as a static test can provide. But what can we do to provide actionable and timely information about performance and reliability when the software is not complete, when the system is not yet assemble or when the software will be deployed in more than one environment? How can you effectively performance test with continuous integration to continually collect feedback on the projectâ€™s performance and scalability characteristics? Eric will deconstruct realism in performance simulation, talk about performance testing more cheaply to test more often and suggest strategies and techniques to get actionable performance feedback throughout a project. He will share findings from WOPR22, where performance testers from around the world came together to discuss this theme in a peer workshop.",
    "favorite": "0",
    "length": "40:32",
    "likes": "0",
    "recorded": "2016-09-14",
    "speakers": [
        "eric-proegler"
    ],
    "tags": [],
    "thumbnail_url": "https://i.ytimg.com/vi/NKDVm_cfMq0/hqdefault.jpg",
    "title": "Continuous Performance Testing Feedback",
    "videos": [
        {
            "code": "NKDVm_cfMq0",
            "type": "youtube"
        }
    ],
    "views": "69"
}